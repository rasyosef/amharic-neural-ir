{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PBO7N5eGq3m6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdd06c6b-1a94-4284-fadf-3d8073dee48f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.1/134.1 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m340.6/340.6 kB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m422.8/422.8 kB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m138.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.5/491.5 kB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.4/77.4 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.3/99.3 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m124.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m88.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m59.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m104.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m98.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m249.2/249.2 kB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m85.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m866.1/866.1 kB\u001b[0m \u001b[31m60.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m75.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.0/288.0 kB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.0/135.0 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.1/45.1 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for warc3-wet-clueweb09 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for cbor (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "! pip install -q sentence-transformers datasets pylate beir ranx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zsM6TlC2rEeQ"
      },
      "outputs": [],
      "source": [
        "import wandb\n",
        "wandb.init(mode=\"disabled\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4sMnlk6QrIHl",
        "outputId": "6e3b42f5-db0c-43c5-be12-61f0d3ebd672"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove 'output/': No such file or directory\n",
            "rm: cannot remove 'pylate-index/': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "! rm -r output/\n",
        "! rm -r pylate-index/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S42Guf_YrKvv"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from datasets import load_dataset\n",
        "from sentence_transformers import (\n",
        "    SentenceTransformerTrainer,\n",
        "    SentenceTransformerTrainingArguments,\n",
        ")\n",
        "\n",
        "from pylate import evaluation, losses, models, utils\n",
        "\n",
        "# Define model parameters for contrastive training\n",
        "model_name = \"rasyosef/roberta-medium-amharic\"  # Choose the pre-trained model you want to use as base\n",
        "batch_size = 32  # Larger batch size often improves results, but requires more memory\n",
        "\n",
        "num_train_epochs = 4  # Adjust based on your requirements\n",
        "# Set the run name for logging and output directory\n",
        "run_name = \"colbert-medium-amharic\"\n",
        "output_dir = f\"output/{run_name}\"\n",
        "\n",
        "# 1. Here we define our ColBERT model. If not a ColBERT model, will add a linear layer to the base encoder.\n",
        "model = models.ColBERT(\n",
        "  model_name_or_path=model_name,\n",
        "  document_length=256\n",
        ")\n",
        "\n",
        "# Compiling the model makes the training faster\n",
        "# model = torch.compile(model)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.query_length, model.document_length"
      ],
      "metadata": {
        "id": "OwyKvH1JKbtx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "feb08f4c-c91e-4e1f-ab05-0e4b26c7cff8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32, 256)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mV0VvIDFrQw5"
      },
      "outputs": [],
      "source": [
        "# Load Dataset\n",
        "from datasets import load_dataset\n",
        "\n",
        "am_relevance_dataset = load_dataset(\"yosefw/amharic-news-retrieval-dataset-v2-with-negatives-V2\")#.select(range(4_000))\n",
        "am_relevance_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2C6LbTAfrVI9",
        "outputId": "bf87df60-8e13-46d3-91ad-0747ac3c44f2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6764"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "test_passage_ids = set(am_relevance_dataset[\"test\"][\"passage_id\"])\n",
        "len(test_passage_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YE9yltORrXlL",
        "outputId": "c346d947-f582-445e-db7e-2f63ebac3751"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 61469/61469 [00:25<00:00, 2383.06it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['query_id', 'passage_id', 'query', 'positive', 'negative_1', 'negative_2', 'negative_3', 'negative_4'],\n",
              "    num_rows: 122938\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "from datasets import Dataset\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "\n",
        "ds_rows = []\n",
        "for row in tqdm(am_relevance_dataset[\"train\"]):\n",
        "  neg_passages = row[\"negative_passages\"]\n",
        "  # neg_passages = list(filter(lambda x: x[\"passage_id\"] not in test_passage_ids, neg_passages))\n",
        "  neg_passages_filtered = neg_passages[:4] + neg_passages[-4:]\n",
        "\n",
        "  ds_rows.append({\n",
        "      \"query_id\": row[\"query_id\"],\n",
        "      \"passage_id\": row[\"passage_id\"],\n",
        "      \"query\": row[\"query\"],\n",
        "      \"positive\": row[\"passage\"],\n",
        "      \"negative_1\": neg_passages_filtered[0][\"passage\"],\n",
        "      \"negative_2\": neg_passages_filtered[2][\"passage\"],\n",
        "      \"negative_3\": neg_passages_filtered[4][\"passage\"],\n",
        "      \"negative_4\": neg_passages_filtered[6][\"passage\"],\n",
        "    })\n",
        "\n",
        "  ds_rows.append({\n",
        "      \"query_id\": row[\"query_id\"],\n",
        "      \"passage_id\": row[\"passage_id\"],\n",
        "      \"query\": row[\"query\"],\n",
        "      \"positive\": row[\"passage\"],\n",
        "      \"negative_1\": neg_passages_filtered[1][\"passage\"],\n",
        "      \"negative_2\": neg_passages_filtered[3][\"passage\"],\n",
        "      \"negative_3\": neg_passages_filtered[5][\"passage\"],\n",
        "      \"negative_4\": neg_passages_filtered[7][\"passage\"],\n",
        "    })\n",
        "  # print(ds_rows)\n",
        "  # break\n",
        "\n",
        "relevance_dataset = Dataset.from_list(ds_rows).sort(\"query_id\")#.select(range(4000))\n",
        "relevance_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MorivAcHrn02",
        "outputId": "757e57d3-91ca-4a72-bb50-f7ec8e0c8f07"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "161"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "len(test_passage_ids.intersection(relevance_dataset[\"passage_id\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eH4B0sn7vDEA"
      },
      "outputs": [],
      "source": [
        "# Split the dataset (this dataset does not have a validation set, so we split the training set)\n",
        "\n",
        "EVAL_SIZE = 4_000\n",
        "\n",
        "eval_dataset = relevance_dataset.select(range(EVAL_SIZE))\n",
        "train_dataset = relevance_dataset.select(range(EVAL_SIZE, len(relevance_dataset)))\n",
        "\n",
        "train_dataset[0], train_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n9wemfSQsygy"
      },
      "outputs": [],
      "source": [
        "eval_dataset[0], eval_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tGpzjM5LvAHX",
        "outputId": "e9c6e45c-d7cf-4b51-a91e-da60ebf2f8bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sentence_transformers.evaluation.TripletEvaluator:The 'main_distance_function' parameter is deprecated. Please use 'main_similarity_function' instead. 'main_distance_function' will be removed in a future release.\n"
          ]
        }
      ],
      "source": [
        "# Define the loss function\n",
        "train_loss = losses.Contrastive(model=model)\n",
        "\n",
        "# Initialize the evaluator\n",
        "dev_evaluator = evaluation.ColBERTTripletEvaluator(\n",
        "    anchors=eval_dataset[\"query\"] * 4,\n",
        "    positives=eval_dataset[\"positive\"] * 4,\n",
        "    negatives=eval_dataset[\"negative_1\"] + eval_dataset[\"negative_2\"] + eval_dataset[\"negative_3\"] + eval_dataset[\"negative_4\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AXdxU0qivIDs"
      },
      "outputs": [],
      "source": [
        "eval_steps = 1000\n",
        "\n",
        "# Configure the training arguments (e.g., batch size, evaluation strategy, logging steps)\n",
        "args = SentenceTransformerTrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "    num_train_epochs=num_train_epochs,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    fp16=True,  # Set to False if you get an error that your GPU can't run on FP16\n",
        "    bf16=False,  # Set to True if you have a GPU that supports BF16\n",
        "    run_name=run_name,  # Will be used in W&B if `wandb` is installed\n",
        "    learning_rate=1e-5,\n",
        "    lr_scheduler_type=\"linear\",\n",
        "    eval_strategy=\"steps\",\n",
        "    eval_steps=eval_steps,\n",
        "    save_strategy=\"steps\",\n",
        "    save_steps=eval_steps,\n",
        "    # save_total_limit=2,\n",
        "    logging_strategy=\"steps\",\n",
        "    logging_steps=eval_steps,\n",
        ")\n",
        "\n",
        "# Initialize the trainer for the contrastive training\n",
        "trainer = SentenceTransformerTrainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    loss=train_loss,\n",
        "    evaluator=dev_evaluator,\n",
        "    data_collator=utils.ColBERTCollator(model.tokenize),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 702
        },
        "id": "CrtX2fj4v2VZ",
        "outputId": "602111e0-11f4-4461-e480-8fe2c60c3bb7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3714' max='14868' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 3714/14868 32:52 < 1:38:45, 1.88 it/s, Epoch 1.00/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.463200</td>\n",
              "      <td>0.290327</td>\n",
              "      <td>0.968125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.321200</td>\n",
              "      <td>0.259508</td>\n",
              "      <td>0.971000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.266100</td>\n",
              "      <td>0.240049</td>\n",
              "      <td>0.973313</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='14868' max='14868' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [14868/14868 2:14:00, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.463200</td>\n",
              "      <td>0.290327</td>\n",
              "      <td>0.968125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.321200</td>\n",
              "      <td>0.259508</td>\n",
              "      <td>0.971000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.266100</td>\n",
              "      <td>0.240049</td>\n",
              "      <td>0.973313</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.226800</td>\n",
              "      <td>0.217545</td>\n",
              "      <td>0.976313</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>0.171200</td>\n",
              "      <td>0.204488</td>\n",
              "      <td>0.978750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>0.158300</td>\n",
              "      <td>0.199975</td>\n",
              "      <td>0.979188</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7000</td>\n",
              "      <td>0.146300</td>\n",
              "      <td>0.194563</td>\n",
              "      <td>0.980188</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8000</td>\n",
              "      <td>0.128300</td>\n",
              "      <td>0.195501</td>\n",
              "      <td>0.980438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9000</td>\n",
              "      <td>0.107700</td>\n",
              "      <td>0.192818</td>\n",
              "      <td>0.980938</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10000</td>\n",
              "      <td>0.106900</td>\n",
              "      <td>0.189652</td>\n",
              "      <td>0.981063</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11000</td>\n",
              "      <td>0.099600</td>\n",
              "      <td>0.188703</td>\n",
              "      <td>0.980813</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12000</td>\n",
              "      <td>0.086200</td>\n",
              "      <td>0.187874</td>\n",
              "      <td>0.980438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13000</td>\n",
              "      <td>0.082300</td>\n",
              "      <td>0.187356</td>\n",
              "      <td>0.981375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14000</td>\n",
              "      <td>0.082100</td>\n",
              "      <td>0.185656</td>\n",
              "      <td>0.981563</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=14868, training_loss=0.1691610871510766, metrics={'train_runtime': 8042.453, 'train_samples_per_second': 59.155, 'train_steps_per_second': 1.849, 'total_flos': 0.0, 'train_loss': 0.1691610871510766, 'epoch': 4.0})"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# Start the training process\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDHAyjnMv7td"
      },
      "source": [
        "### **Evaluate**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1jBGFzqCv-ks",
        "outputId": "56e746ba-4165-4144-ba1d-0d1dd0607cac"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.9816875457763672}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "dev_evaluator(\n",
        "    model=model,\n",
        "    # model=models.ColBERT(\"/content/output/contrastive-bert-small/checkpoint-2850\"),\n",
        "    output_path=\".\"\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rIeLfIh80me6"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"HF_TOKEN\"] = userdata.get(\"HF_WRITE\")\n",
        "\n",
        "# push model to hub\n",
        "# trainer.model.push_to_hub(\"ColBERT-Amharic-Medium\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6XflwT_1Sqh"
      },
      "source": [
        "### **BIER Eval**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EzVfNqYzwAqz"
      },
      "outputs": [],
      "source": [
        "from pylate import evaluation, indexes, models, retrieve\n",
        "\n",
        "# Step 1: Initialize the ColBERT model\n",
        "\n",
        "# dataset = \"scifact\" # Choose the dataset you want to evaluate\n",
        "model = models.ColBERT(\n",
        "    model_name_or_path=\"rasyosef/ColBERT-Amharic-Medium\",\n",
        "    device=\"cuda\" # \"cpu\" or \"cuda\" or \"mps\"\n",
        ")\n",
        "\n",
        "# Step 2: Create a Voyager index\n",
        "index = indexes.Voyager(\n",
        "    index_folder=\"pylate-index\",\n",
        "    index_name=\"colbert-eval\",\n",
        "    override=True,  # Overwrite any existing index\n",
        ")\n",
        "\n",
        "test_dataset = am_relevance_dataset[\"test\"]\n",
        "\n",
        "documents = [\n",
        "    {\"id\": pid, \"text\": pos}\n",
        "    for pid, pos in dict(zip(\n",
        "        am_relevance_dataset[\"test\"][\"passage_id\"] + am_relevance_dataset[\"train\"][\"passage_id\"],\n",
        "        am_relevance_dataset[\"test\"][\"passage\"] + am_relevance_dataset[\"train\"][\"passage\"]\n",
        "    )).items()\n",
        "  ]\n",
        "\n",
        "queries = [q for q in test_dataset[\"query\"]]\n",
        "qrels = {query: {pid:1} for query, pid in zip(test_dataset[\"query\"], test_dataset[\"passage_id\"])}\n",
        "\n",
        "# Step 4: Encode the documents\n",
        "documents_embeddings = model.encode(\n",
        "    [document[\"text\"] for document in documents],\n",
        "    batch_size=32,\n",
        "    is_query=False,  # Indicate that these are documents\n",
        "    show_progress_bar=True,\n",
        ")\n",
        "\n",
        "# Step 5: Add document embeddings to the index\n",
        "index.add_documents(\n",
        "    documents_ids=[document[\"id\"] for document in documents],\n",
        "    documents_embeddings=documents_embeddings,\n",
        ")\n",
        "\n",
        "# Step 6: Encode the queries\n",
        "queries_embeddings = model.encode(\n",
        "    queries,\n",
        "    batch_size=32,\n",
        "    is_query=True,  # Indicate that these are queries\n",
        "    show_progress_bar=True,\n",
        ")\n",
        "\n",
        "# Step 7: Retrieve top-k documents\n",
        "retriever = retrieve.ColBERT(index=index)\n",
        "scores = retriever.retrieve(\n",
        "    queries_embeddings=queries_embeddings,\n",
        "    k=100,  # Retrieve the top 100 matches for each query\n",
        "    batch_size=128,\n",
        ")\n",
        "\n",
        "# Step 8: Evaluate the retrieval results\n",
        "results = evaluation.evaluate(\n",
        "    scores=scores,\n",
        "    qrels=qrels,\n",
        "    queries=queries,\n",
        "    metrics=[f\"ndcg@{k}\" for k in [5, 10, 100]] # NDCG for different k values\n",
        "    + [\"recall@5\", \"recall@10\", \"recall@50\", \"recall@100\"]   # Recall at k\n",
        "    + [\"mrr@5\", \"mrr@10\", \"mrr@100\"]\n",
        ")\n",
        "\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VlfTsRMYwVLm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f9570c1-1ee1-427e-fe74-4c6631d384db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'ndcg@5': np.float64(0.8008276603008163), 'ndcg@10': np.float64(0.8111646117466479), 'ndcg@100': np.float64(0.8228976121185352), 'recall@5': np.float64(0.8819566490919742), 'recall@10': np.float64(0.9137375512595196), 'recall@50': np.float64(0.9565026362038664), 'recall@100': np.float64(0.9685120093731693), 'mrr@5': np.float64(0.7733401679359501), 'mrr@10': np.float64(0.7776421899554589), 'mrr@100': np.float64(0.7800789457297966)}\n",
            "ndcg@5: 0.8008276603008163\n",
            "ndcg@10: 0.8111646117466479\n",
            "ndcg@100: 0.8228976121185352\n",
            "mrr@5: 0.7733401679359501\n",
            "mrr@10: 0.7776421899554589\n",
            "mrr@100: 0.7800789457297966\n",
            "recall@5: 0.8819566490919742\n",
            "recall@10: 0.9137375512595196\n",
            "recall@50: 0.9565026362038664\n",
            "recall@100: 0.9685120093731693\n"
          ]
        }
      ],
      "source": [
        "# Step 8: Evaluate the retrieval results\n",
        "results = evaluation.evaluate(\n",
        "    scores=scores,\n",
        "    qrels=qrels,\n",
        "    queries=queries,\n",
        "    metrics=[f\"ndcg@{k}\" for k in [5, 10, 100]] # NDCG for different k values\n",
        "    + [\"recall@5\", \"recall@10\", \"recall@50\", \"recall@100\"]   # Recall at k\n",
        "    + [\"mrr@5\", \"mrr@10\", \"mrr@100\"]\n",
        ")\n",
        "\n",
        "print(results)\n",
        "\n",
        "metrics = [\"ndcg@5\", \"ndcg@10\", \"ndcg@100\", \"mrr@5\", \"mrr@10\", \"mrr@100\", \"recall@5\", \"recall@10\", \"recall@50\", \"recall@100\"]\n",
        "for m in metrics:\n",
        "  print(f\"{m}: {results[m]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oCwpVBZjPsyV"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}